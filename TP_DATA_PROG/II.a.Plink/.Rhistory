linear_model <- lm(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason, data = Prostate)
summary(linear_model)
plot(linear_model)
?aic
??aic
?stepAIC
step_model <- stepAIC(linear_model, direction = "both", trace = 1)
step_model
?anova
small_model <- lm(lpsa ~ lcavol + lweight + svi, data = Prostate)
summary(small_model)
anova(small_model, linear_model)
anova(linear_model, small_model)
X <- as.matrix(Pima[c("pregnant", "glucose", "pressure", "triceps", "insulin", "mass", "pedigree", "age")])
y <- as.vector(Pima["diabetes"])
lasso_pima <- glmnet(X, y, family = "binomial", alpha = 1)
View(y)
y <- Pima["diabetes"]
lasso_pima <- glmnet(X, y, family = "binomial", alpha = 1)
View(X)
View(y)
View(X)
class(X)
X <- as.matrix(Pima[c("pregnant", "glucose", "pressure", "triceps", "insulin", "mass", "pedigree", "age")])
y <- Pima["diabetes"]
lasso_pima <- glmnet(X, y, family = "binomial", alpha = 1)
?rbinom
pbinom(0:5, prob=1/2, size=5)
dbinom(0:5, prob = 1/2, size =5)
dbinom(0:5, prob = 6/10, size =5)
pbinom(0:5, prob=6/10, size=5)
quantileH0
n = 30
p = 6/10
quantileH0 <- qbinom(0.95, prob = 1/2, size = n)
quantileH0
pbinom(quantileH0-1, prob = p, size = n, lower.tail = F)
simu <- rbinom(10^4, prob = p, size = n)
head(simu)
res1 <- pbinom(simu, prob = 1/2, size = n)
head(signif(res1, 2))
sum(res1 >= 0.95 / 10^4)
sum(res1 >= 0.95) / 10^4
n <- 100
p <- 6/10
repet <- 100000
quantileH0 <- qbinom(0.95, prob = 1/2, size = n)
quantileH0
pbinom(quantileH0-1, prob = p, size = n, lower.tail = F)
simu <- rbinom(10^4, prob = p, size = n)
head(simu)
res1 <- pbinom(simu, prob = 1/2, size = n)
head(res1)
sum(res1 >= 0.95) / 10^4
quantileH0 <- qbinom(0.95, prob = 1/2, size = n)
calculPuissance <- function(n, p = 6/10) {
quantileH0 <- qbinom(0.95, prob = 1/2, size = n)
return(1-pbinom(quantileH0-1, prob = p, size = n))
}
ns <- 1:30*10
Puissance <- sapply(ns, FUN = calculPuissance)
plot(ns, Puissance, lwd = 2, type = "1", col = "red")
plot(ns, Puissance, lwd = 2, type = "l", col = "red")
computePower <- function(n,p.H1 = 6/10){
alpha = 0.05
p.H0 = 1/2
quantile <- qbinom(1-alpha, n,p.H0)
power = pbinom(quantile-1, n,p.H1, lower.tail = FALSE)
return(power)
}
sample.sizes <- (10:300)
results <- sapply(sample.sizes, computePower)
head(results)
plot(sample.sizes, results, lwd = 2, type = "l", col = "red")
t(rmultinom(1, prob = rep(1,6)/6, size =1))
x <- rmultinom(1, prob = rep(c(1,2), c(5,1))/ 7, size = 100)
chisq.test(x)$p.value
chisq.test(rmultinom(1, prob = pH1_, size = n))$p.value
simu.chi <- function(n, pH1){
chisq.test(rmultinom(1, prob = pH1, size = n))$p.value
}
m.simu.chi <- function(n, pH1, alpha, repet){
p.v <- sapply(rep(n, repet), FUN = simu.chi, pH1 = pH1)
sum(p.v) <= alpha/repet
}
ns <- 1:40 * 10
# H1 -> 2/6 to get 6, 1/7 to get 1-5
pH1 <- c(1,1,1,1,1,2)/7
pow.chi <- sapply(ns, FUN = m.simu.chi, pH1 = pH1, alpha = 0.05, repet = 10^3)
plot(ns, pow.chi, type = "l", lwd = 2, col = c("blue"), xlab = "n", ylab = "Prob Detection")
warnings()
m.simu.chi <- function(n, pH1, alpha, repet){
p.v <- sapply(1:repet, FUN = simu.chi, n = n, pH1 = pH1)
sum(p.v) <= alpha/repet
}
ns <- 1:40 * 10
# H1 -> 2/6 to get 6, 1/7 to get 1-5
pH1 <- c(1,1,1,1,1,2)/7
pow.chi <- sapply(ns, FUN = m.simu.chi, pH1 = pH1, alpha = 0.05, repet = 10^3)
plot(ns, pow.chi, type = "l", lwd = 2, col = c("blue"), xlab = "n", ylab = "Prob Detection")
m.simu.chi <- function(n, pH1, alpha, repet){
p.v <- sapply(rep(n, repet), FUN = simu.chi, pH1 = pH1)
sum(p.v <= alpha)/repet
}
ns <- 1:40 * 10
# H1 -> 2/6 to get 6, 1/7 to get 1-5
pH1 <- c(1,1,1,1,1,2)/7
pow.chi <- sapply(ns, FUN = m.simu.chi, pH1 = pH1, alpha = 0.05, repet = 10^3)
plot(ns, pow.chi, type = "l", lwd = 2, col = c("blue"), xlab = "n", ylab = "Prob Detection")
total_n <- 20
alpha <- 0.05
delta <- 1
total_n <- 20
compute_power <- function(n1, n2, delta, alpha = 0.05){
# for variance = 1
se <- sqrt(1/n1 + 1/n2)
#degrees of freedom
df <- n1 + n2 - 2
t_crit <- qt(1-alpha/2, df = df)
# under the H1, T = delta/se
mean_t <- delta/se
# Approximate power using normal approximation for large-ish n:
# Power = P(T > t_crit) given T ~ Normal(mean_t, 1)
#       = P(Z > t_crit - mean_t)
# where Z ~ N(0,1)
power <- 1 - pnorm(t_crit - mean_t)
return(power)
}
n1_values <- 1:19
power_values <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power(n1, n2, delta = 1, alpha = 0.05)
})
plot(n1_values, power_values, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 1")
power_values_d2 <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power(n1, n2, delta = 2, alpha = 0.05)
})
plot(n1_values, power_values_d2, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 2")
compute_power <- function(n1, n2, delta, alpha = 0.05){
# for variance = 1
se <- sqrt(1/n1 + 1/n2)
#degrees of freedom for is we didn't know the distribution was N
#df <- n1 + n2 - 2
t_crit <- qnorm(1-alpha/2)
# under the H1, T = delta/se
mean_t <- delta/se
# Approximate power using normal approximation for large-ish n:
# Power = P(T > t_crit) given T ~ Normal(mean_t, 1)
#       = P(Z > t_crit - mean_t)
# where Z ~ N(0,1)
power <- 1 - pnorm(t_crit - mean_t)
return(power)
}
n1_values <- 1:19
power_values <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power(n1, n2, delta = 1, alpha = 0.05)
})
plot(n1_values, power_values, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 1")
power_values_d2 <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power(n1, n2, delta = 2, alpha = 0.05)
})
plot(n1_values, power_values_d2, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 2")
n1_values <- 3:17 # because you need some variance in your life, not 1:19
power_values <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power(n1, n2, delta = 1, alpha = 0.05)
})
plot(n1_values, power_values, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 1")
power_values_d2 <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power(n1, n2, delta = 2, alpha = 0.05)
})
plot(n1_values, power_values_d2, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 2")
compute_power_nonN <- function(n1, n2, delta, alpha = 0.05){
# for variance = 1
se <- sqrt(1/n1 + 1/n2)
#degrees of freedom for is we didn't know the distribution was N
df <- n1 + n2 - 2
t_crit <- qt(1-alpha/2, df = df)
# under the H1, T = delta/se
mean_t <- delta/se
# Approximate power using normal approximation for large-ish n:
# Power = P(T > t_crit) given T ~ Normal(mean_t, 1)
#       = P(Z > t_crit - mean_t)
# where Z ~ N(0,1)
power <- 1 - pnorm(t_crit - mean_t)
return(power)
}
power_values_d3 <- sapply(n1_values, function(n1) {
n2 <- total_n - n1
compute_power_nonN(n1, n2, delta = 3, alpha = 0.05)
})
plot(n1_values, power_values_d3, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 2")
plot(n1_values, power_values_d3, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 3")
e
n1_values_nonN <- 3:98
power_values_d3 <- sapply(n1_values_nonN, function(n1) {
n2 <- total_n - n1
compute_power_nonN(n1, n2, delta = 3, alpha = 0.05)
})
plot(n1_values_nonN, power_values_d3, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 3")
total_n2 <- 101
n1_values_nonN <- 3:98
power_values_d3 <- sapply(n1_values_nonN, function(n1) {
n2 <- total_n2 - n1
compute_power_nonN(n1, n2, delta = 3, alpha = 0.05)
})
plot(n1_values_nonN, power_values_d3, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 3")
total_n2 <- 91
n1_values_nonN <- 3:88
power_values_d3 <- sapply(n1_values_nonN, function(n1) {
n2 <- total_n2 - n1
compute_power_nonN(n1, n2, delta = 3, alpha = 0.05)
})
plot(n1_values_nonN, power_values_d3, type = "b", pch = 19, xlab = "n1", ylab = "Power", main = "Power to detect the difference in 3")
n1_candidates <- 1:24
powers <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers[i] <- compute_power_nonN(n1, n2, delta = 3, alpha)
} else{
powers[i] <- NA
}
}
plot(n1_candidates, powers, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power",
main="Power to detect difference of 3 with given budget")
compute_power_nonN <- function(n1, n2, delta, alpha = 0.05) {
# Given variance = 1
se <- sqrt(1/n1 + 1/n2)
df <- n1 + n2 - 2
# Critical value for two-sided test
t_crit <- qt(1 - alpha/2, df = df)
# Non-centrality parameter: difference over standard error
lambda <- delta / se
# Under H1, T ~ non-central t(df, ncp=lambda)
# Power = P(T < -t_crit) + P(T > t_crit)
# Using the non-central t CDF (pt):
p_lower <- pt(-t_crit, df = df, ncp = lambda)
p_upper <- 1 - pt(t_crit, df = df, ncp = lambda)
power <- p_lower + p_upper
return(power)
}
n1_candidates <- 1:24
powers <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers[i] <- compute_power_nonN(n1, n2, delta = 3, alpha)
} else{
powers[i] <- NA
}
}
plot(n1_candidates, powers, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power",
main="Power to detect difference of 3 with given budget")
n1_candidates <- 1:24
powers <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers[i] <- compute_power_nonN(n1, n2, delta = 2, alpha)
} else{
powers[i] <- NA
}
}
plot(n1_candidates, powers, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power",
main="Power to detect difference of 3 with given budget")
powers == max(powers)
n1_candidates <- 3:24
powers <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers[i] <- compute_power_nonN(n1, n2, delta = 2, alpha)
} else{
powers[i] <- NA
}
}
plot(n1_candidates, powers, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power",
main="Power to detect difference of 3 with given budget")
powers == max(powers)
n1_candidates <- 3:24
powers <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers[i] <- compute_power_nonN(n1, n2, delta = 3, alpha)
} else{
powers[i] <- NA
}
}
plot(n1_candidates, powers, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power",
main="Power to detect difference of 3 with given budget")
powers == max(powers)
?pt
print(powers)
compute_power_nonN_cor <- function(n1, n2, delta, v1_estim, v2_estim, alpha = 0.05) {
# Compute pooled variance
sp2 <- ((n1 - 1)*v1_estim + (n2 - 1)*v2_estim) / (n1 + n2 - 2)
# Standard error using the pooled variance
sCor <- sqrt((1/n1 + 1/n2)*sp2)
# Degrees of freedom
df <- n1 + n2 - 2
# Critical t-value for a two-sided test
t_crit <- qt(1 - alpha/2, df = df)
# Non-centrality parameter (delta / SE)
lambda <- delta / sCor
# Compute power using the non-central t-distribution:
# Power = P(T < -t_crit) + P(T > t_crit)
p_lower <- pt(-t_crit, df = df, ncp = lambda)
p_upper <- 1 - pt(t_crit, df = df, ncp = lambda)
power <- p_lower + p_upper
return(power)
}
compute_power_nonN_cor <- function(n1, n2, delta, v1_estim, v2_estim, alpha = 0.05) {
# Compute pooled variance
sp2 <- ((n1 - 1)*v1_estim + (n2 - 1)*v2_estim) / (n1 + n2 - 2)
# Standard error using the pooled variance
sCor <- sqrt((1/n1 + 1/n2)*sp2)
# Degrees of freedom
df <- n1 + n2 - 2
# Critical t-value for a two-sided test
t_crit <- qt(1 - alpha/2, df = df)
# Non-centrality parameter (delta / SE)
lambda <- delta / sCor
# Compute power using the non-central t-distribution:
# Power = P(T < -t_crit) + P(T > t_crit)
p_lower <- pt(-t_crit, df = df, ncp = lambda)
p_upper <- 1 - pt(t_crit, df = df, ncp = lambda)
power <- p_lower + p_upper
return(power)
}
powers_cor <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers_cor[i] <- compute_power_nonN_cor(n1, n2, delta = 3, alpha)
} else{
powers_cor[i] <- NA
}
}
plot(n1_candidates, powers_cor, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power_cor",
main="Corrected power to detect difference of 3 with given budget")
powers_cor == max(powers_cor)
compute_power_nonN_cor <- function(n1, n2, delta, v1_estim, v2_estim, alpha = 0.05) {
# Compute pooled variance
v1_estim = 1
v2_estim = 1
sp2 <- ((n1 - 1)*v1_estim + (n2 - 1)*v2_estim) / (n1 + n2 - 2)
# Standard error using the pooled variance
sCor <- sqrt((1/n1 + 1/n2)*sp2)
# Degrees of freedom
df <- n1 + n2 - 2
# Critical t-value for a two-sided test
t_crit <- qt(1 - alpha/2, df = df)
# Non-centrality parameter (delta / SE)
lambda <- delta / sCor
# Compute power using the non-central t-distribution:
# Power = P(T < -t_crit) + P(T > t_crit)
p_lower <- pt(-t_crit, df = df, ncp = lambda)
p_upper <- 1 - pt(t_crit, df = df, ncp = lambda)
power <- p_lower + p_upper
return(power)
}
powers_cor <- numeric(length(n1_candidates))
for (i in seq_along(n1_candidates)) {
n1 <- n1_candidates[i]
n2 <- 100 - 4*n1
if (n2 > 0) {
powers_cor[i] <- compute_power_nonN_cor(n1, n2, delta = 3, alpha)
} else{
powers_cor[i] <- NA
}
}
plot(n1_candidates, powers_cor, type="b", pch=19, xlab="n1 (Healthy)", ylab="Power_cor",
main="Corrected power to detect difference of 3 with given budget")
powers_cor == max(powers_cor)
print(powers_cor)
theta_range <- seq(0.06, 0.08, by = 0.001)
theta_range <- seq(0.06, 0.08, by = 0.001)
setwd('C:/Users/denis/OneDrive/Desktop/Uni/NGS/Project/TP_DATA_PROG/TP_DATA_PROG/I.a.Paramlink')
fam = read.table('fam.txt')
fam[1:5, 1:10]
x = linkdat(fam)
summary(x)
plot(x, marker=1)
xdom = setModel(x, model=1, penetrances = c(0.00001, 1, 1), dfreq = 0.00001)
result = lod(xdom, theta=c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5))
result_df = as.data.frame(result)
write.csv(result_df, "lod_results.csv", row.names = TRUE)
zmax_minus_11 <- 6.6738
theta_range <- seq(0.06, 0.08, by = 0.001)
for (theta in theta_range) {
# Compute the LOD score for the current theta
result <- lod(xdom, theta = theta)
# Check if the first column matches the zmax - 1 value
if (result[, 1] > zmax_minus_11) {
print(paste("Theta at zmax - 1 is:", theta))
print(result)
break
}
}
lod(xdom, marker=c(5,7,8,12), theta='max')
library(paramlink)
fam = read.table('fam.txt')
fam[1:5, 1:10]
x = linkdat(fam)
summary(x)
plot(x, marker=1)
xdom = setModel(x, model=1, penetrances = c(0.00001, 1, 1), dfreq = 0.00001)
result = lod(xdom, theta=c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5))
result_df = as.data.frame(result)
write.csv(result_df, "lod_results.csv", row.names = TRUE)
zmax_minus_11 <- 6.6738
theta_range <- seq(0.06, 0.08, by = 0.001)
for (theta in theta_range) {
# Compute the LOD score for the current theta
result <- lod(xdom, theta = theta)
# Check if the first column matches the zmax - 1 value
if (result[, 1] > zmax_minus_11) {
print(paste("Theta at zmax - 1 is:", theta))
print(result)
break
}
}
lod(xdom, marker=c(5,7,8,12), theta='max')
xdom5=modifyMarker(xdom,marker = 5, afreq = c(0.1, 0.1, 0.1, 0.7))
lod(xdom5, marker=5, theta=c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5))
xrec=setModel(x, model=2, penetrances=c(0.00001,0.00001, 1), dfreq=0.00001)
result_rec = lod(xrec)
result_rec_df = as.data.frame(result_rec)
write.csv(result_rec_df, "lod_results_rec.csv", row.names = TRUE)
result_rec2 = lod(xrec, theta=c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5))
result_rec2_df = as.data.frame(result_rec2)
write.csv(result_rec2_df, "lod_results_rec2.csv", row.names = TRUE)
setwd ('C:/Users/denis/OneDrive/Desktop/Uni/NGS/Project/TP_DATA_PROG/TP_DATA_PROG/II.a.Plink')
# Load the association results
assoc <- read.table("res_allelic.assoc", header = TRUE)
# Count SNPs with p < 0.05
significant_snps <- nrow(assoc[assoc$P < 0.05, ])
# Bonferroni correction threshold
bonferroni_threshold <- 0.05 / nrow(assoc)
# Count SNPs with p < Bonferroni threshold
bonferroni_snps <- nrow(assoc[assoc$P < bonferroni_threshold, ])
# Output results
cat("Number of SNPs with p < 0.05:", significant_snps, "\n")
cat("Bonferroni-adjusted p-value threshold:", bonferroni_threshold, "\n")
cat("Number of SNPs with p < Bonferroni threshold:", bonferroni_snps, "\n")
coch <- read.table("res_geno.assoc.logistic")
View(coch)
coch <- read.table("res_geno.assoc.logistic", header = TRUE)
snps_coch <- nrow(coch[coch$P < 0.05, ])
bonf_t_coch <- 0.05 / nrow(coch)
cat("Number of SNPs with p < 0.05", snps_coch, "\n")
cat("Bonferroni-adjusted p-value threshold:", bonf_t_coch, "\n")
bonf_snps_coch <- nrow(coch(coch$P < bonf_t_coch, "\n"))
bonf_snps_coch <- nrow(coch$P < bonf_t_coch, "\n")
bonf_snps_coch <- nrow(coch[coch$P < bonf_t_coch, ])
cat("Number of SNPs with p < Bonferroni threshold:", bonf_snps_coch)
geno <- read.table("res_geno.assoc.logistic", header = TRUE)
geno_significant_snps <- nrow(geno[geno$P < 0.05, ])
geno_bonf_t <- 0.05 / nrow(geno)
geno_bonf_snps <- nrow(geno[geno$P < geno_bonf_t, ])
cat("Number of SNPs with p < 0.05", snps_coch, "\n")
cat("Bonferroni-adjusted p-value threshold:", bonf_t_coch, "\n")
cat("Number of SNPs with p < Bonferroni threshold:", bonf_snps_coch)
for (line in nrow(geno)) {
if (geno[geno$P < geno_bonf_t, ]) {
print(geno(, line))
}
}
for (line in 1:nrow(geno)) {
if (geno$P[line] < geno_bonf_t) {
print(geno[line, ])
}
}
for (line in 1:nrow(geno)) {
if (geno$P[line] < geno_bonf_t) {
print(geno[line, ])
}
}
for (line in 1:nrow(geno)) {
if (!is.na(geno$P[line]) && geno$P[line] < geno_bonf_t) {
print(geno[line, ])
}
}
for (line in 1:nrow(geno)) {
if (is.na(geno$P[line])) {
print(geno[line, ])
}
}
for (line in 1:nrow(assoc)) {
if (is.na(assoc$P[line])) {
print(assoc[line, ])
}
}
geno$BH_p <- p.adjust(geno$P, method = 'BH')
fdr_thresh <- 0.05
sigma_snps <- geno[geno$BH_p < fdr_thresh, ]
cat("Number of significant SNPs (FDR < 0.05):", nrow(significant_snps), "\n")
print(significant_snps)
cat("Number of significant SNPs (FDR < 0.05):", nrow(sigma_snps), "\n")
print(sigma_snps)
